name,description,version,identifier,category,lastUpdate,label,location,relatesTo,requires,requiredBy,isBefore,isAfter
Data access and ethics,Determine data access for FAIRification,2020-12-01,process-7201634925228134237,processes,2021-02-05,"accessibility, hosting",,process-8298344911298610653,,,process-8298344911298610653,
Interim hosting,"Host data in interim solution and make available for FAIRification processes.
",2020-12-01,process-8298344911298610653,processes,2021-02-05,"accessibility, hosting",,"process238355532526975171, process-7201634925228134237",,,process238355532526975171,process-7201634925228134237
Long term hosting,"Match data types to available hosting solutions eg. public repos, EFPIA cloud.
Examine dataset hosting choices and needs (size, complexity, analytics)
",2020-12-01,process238355532526975171,processes,2021-02-05,"accessibility, hosting",,"process-568280961313138723, process-8298344911298610653",,,process-568280961313138723,process-8298344911298610653
Data Usability Goals,"Define desired and expected outcomes of FAIRification.
",2020-12-01,process-568280961313138723,processes,2021-02-05,,,"process6303934084986307113, process238355532526975171",,,process6303934084986307113,process238355532526975171
Competency questions,"Determine competency questions for FAIRification
",2020-12-01,process6303934084986307113,processes,2021-02-05,,,"process-4022619904400672439, process-568280961313138723",,,process-4022619904400672439,process-568280961313138723
Examination,"Dataset owners 
and FAIR experts examine datasets and reach shared understanding
",2020-12-01,process-4022619904400672439,processes,2021-02-05,,,"process-5053427395880553195, process6303934084986307113",,,process-5053427395880553195,process6303934084986307113
Understand data types,Identify Data Types and primary organising principles,2020-12-01,process-5053427395880553195,processes,2021-02-05,,,"process-4542955192858635464, process-4022619904400672439",,,process-4542955192858635464,process-4022619904400672439
Identifier strategies,"Determine identifier strategy for data types. 
Assign identifiers in accordance with strategy.
Mapping identifiers to established data sources



",2020-12-01,process-4542955192858635464,processes,2021-02-05,,,"process514831807475787382, process-5053427395880553195",,,process514831807475787382,process-5053427395880553195
Metadata strategies,"Determine  project metadata strategies using FAIRsharing.
Apply metadata strategies to datasets.
",2020-12-01,process514831807475787382,processes,2021-02-05,"accessibility, findability, reusability,interoperability, http://edamontology.org/topic_0219",,"process4797913240548361534, process-4542955192858635464",indicator8273044894976530631,,process4797913240548361534,process-4542955192858635464
Evaluate against standards,"Compare datasets to community standards.
Evaluate datasets using FAIR indicators that are appropriate given competency questions

",2020-12-01,process4797913240548361534,processes,2021-02-05,reusability,,"process-8491626043857545931, process514831807475787382",,,process-8491626043857545931,process514831807475787382
Ontology strategies,"Determine  project ontology strategies using FAIRsharing.
Apply ontology strategies to datasets.
",2020-12-01,process-8491626043857545931,processes,2021-02-05,"interoperability, http://edamontology.org/topic_0219",,"process4521070458167520677, process4797913240548361534",tool5428549736443096969,,process4521070458167520677,process4797913240548361534
Interoperability requirements,"Determine interoperability requirement for dataset  (eg. consumption of data for downstream analysis)

",2020-12-01,process4521070458167520677,processes,2021-02-05,"interoperability, http://edamontology.org/data_2353",,"process8430680201372698036, process-8491626043857545931",,,process8430680201372698036,process-8491626043857545931
Data sharing,Submit data to chosen hosting solution for public sharing and dissemination.,2020-12-01,process8430680201372698036,processes,2021-02-05,accessibility,,process4521070458167520677,,,,process4521070458167520677
Who should read this book ?,,,Recipe6324936043312235027,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/introduction/FAIR-cookbook-audience.html,,,,,
What is FAIR ?,,,Recipe5236459522169274466,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/introduction/fair-principle.html,,,,,
The Values of FAIR,,,Recipe-881604471847787996,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/introduction/FAIRplus-values.html,,,,,
What is IMI ?,,,Recipe-3383924512047840448,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/introduction/what-is-IMI.html,,,,,
IMI and Data Management,,,Recipe-7700859528835864133,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/introduction/IMI-and-data-management-plans.html,,,,,
FAIR in IMI context,,,Recipe-6288877472617882048,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/introduction/FAIR-in-IMI-context.html,,,,,
Models for Data Sharing,,,Recipe789539873089433740,recipes,2021-02-05,"accessibility, data sharing,",https://fairplus.github.io/cookbook-dev/recipes/introduction/data-sharing-models.html,,,,,
Infrastructure for FAIR,,,Recipe8934294842260657175,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/infrastructure.html,,,,,
Identifier Resolution Service,,,Recipe4221883301455841347,recipes,2021-02-05,"ontology, reusability, interoperability",https://fairplus.github.io/cookbook-dev/recipes/infrastructure/id-resolution.html,,,,,
Deploying Vocabulary Servers,,,Recipe-8091542677457665571,recipes,2021-02-05,"ontology, reusability, interoperability",https://fairplus.github.io/cookbook-dev/recipes/infrastructure/UC3_R13_local_ontology_services.html,,tool-8908719240678650787,,,
Selecting Terminology Services,,,Recipe-896965399320440267,recipes,2021-02-05,"ontology, reusability, interoperability",https://fairplus.github.io/cookbook-dev/recipes/infrastructure/Selecting_and_using_ontology_lookup_services.html,,,,,
Criteria for selecting Ontology Services,,,Recipe-7889391725481858659,recipes,2021-02-05,"ontology, reusability, interoperability",https://fairplus.github.io/cookbook-dev/recipes/infrastructure/technical-and-architectural-selection-criteria-of-ontology-lookup-services.html,,,,,
Chemical identities - Generating InChI and SMILES strings,,,Recipe-3642283697628185524,recipes,2021-02-05,chemical compound,https://fairplus.github.io/cookbook-dev/recipes/infrastructure/chemical-identities.html,,,,,
Building a Data Catalogue,,,Recipe-3936733753791632470,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/infrastructure/data-catalog.html,,,,,
Deploying the FAIRplus IMI Data Catalogue,,,Recipe-3078866030015924615,recipes,2021-02-05,data hosting,https://fairplus.github.io/cookbook-dev/recipes/infrastructure/data-catalog-deployment.html,,,,,
Findability,,,Recipe-3178843587355057139,recipes,2021-02-05,interoperability,https://fairplus.github.io/cookbook-dev/recipes/findability.html,,,,,
How to create persistent resolvable identifiers,,,Recipe-6827705281216328724,recipes,2021-02-05,findability,https://fairplus.github.io/cookbook-dev/recipes/findability/identifiers.html,,,,,
Depositing to a Data Catalogue - The Zenodo example,,,Recipe7457494795732116146,recipes,2021-02-05,"findability,data deposition",https://fairplus.github.io/cookbook-dev/recipes/findability/zenodo-deposition.html,,,,,
Search Engine Optimization,,,Recipe-4791075659600896223,recipes,2021-02-05,findability,https://fairplus.github.io/cookbook-dev/recipes/findability/seo.html,,,,,
Marking up Data Catalog with Bioschema,,,Recipe-2379942277813382531,recipes,2021-02-05,findability,https://fairplus.github.io/cookbook-dev/recipes/findability/seo/bioschemas-datacatalog.html,,,,,
Marking up Dataset with Bioschema,,,Recipe157538649219840394,recipes,2021-02-05,findability,https://fairplus.github.io/cookbook-dev/recipes/findability/seo/bioschemas-dataset.html,,,,,
Marking up Datapage with Bioschema,,,Recipe5361423758508218422,recipes,2021-02-05,findability,https://fairplus.github.io/cookbook-dev/recipes/findability/seo/bioschemas-data-page.html,,,,,
Accessibility,,,Recipe-208373016948081259,recipes,2021-02-05,findability,https://fairplus.github.io/cookbook-dev/recipes/accessibility.html,,,,,
Anonymization Recipe,,,Recipe-2295955872605358307,recipes,2021-02-05,accessibility,https://fairplus.github.io/cookbook-dev/recipes/accessibility/anonymization.html,,,,,
File Transfer via sFTP,,,Recipe-7422457256790050212,recipes,2021-02-05,accessibility,https://fairplus.github.io/cookbook-dev/recipes/accessibility//how-to-use-sftp-for-transfer.html,,,,,
Fast File Transfer via Aspera,,,Recipe-1640013777693684134,recipes,2021-02-05,accessibility,https://fairplus.github.io/cookbook-dev/recipes/accessibility/aspera.html,,,,,
Interoperability,,,Recipe-9144035994614464874,recipes,2021-02-05,interoperability,https://fairplus.github.io/cookbook-dev/recipes/interoperability.html,,,,,
How to select ontologies,,,Recipe4573982643673564155,recipes,2021-02-05,interoperability,https://fairplus.github.io/cookbook-dev/recipes/interoperability/selecting-ontologies.html,,"tool5428549736443096969,tool93103256108442864 ",,,
How to request new terms in existing ontologies,,,Recipe2577878569038449988,recipes,2021-02-05,interoperability,https://fairplus.github.io/cookbook-dev/recipes/interoperability/ontology-new-term-request-recipe.html,,,,,
How to build an application ontology,,,Recipe-6890535108822254424,recipes,2021-02-05,interoperability,https://fairplus.github.io/cookbook-dev/recipes/interoperability/ontology-robot-recipe.html,,,,,
MSIO robot build process,,,Recipe-6161838023345342107,recipes,2021-02-05,interoperability,https://fairplus.github.io/cookbook-dev/recipes/interoperability/ontology-robot/MSIO-robot-build-process.html,,,,,
Minimal MetaData Profiles,,,Recipe-7529531149130445305,recipes,2021-02-05,interoperability,https://fairplus.github.io/cookbook-dev/recipes/interoperability/creating-minimal-metadata-profiles.html,,,,,
A Transcriptomics MetaData Profile,,,Recipe-7161069174892538972,recipes,2021-02-05,interoperability,https://fairplus.github.io/cookbook-dev/recipes/interoperability/transcriptomics-metadata.html,,,,,
Covid19 Sample MetaData Profile Shex Validation,,,Recipe195591565005687541,recipes,2021-02-05,interoperability,https://fairplus.github.io/cookbook-dev/recipes/interoperability/covid19-sample-metadata-profile-shex-use-case.html,,,,,
How to validate file formats,,,Recipe187102006286812842,recipes,2021-02-05,interoperability,https://fairplus.github.io/cookbook-dev/recipes/interoperability/fastq-file-format-validators.html,,,,,
How to convert to open format from propriatory,,,Recipe5100759266221111572,recipes,2021-02-05,interoperability,https://fairplus.github.io/cookbook-dev/recipes/interoperability/from-proprietary-to-open-standard-mzml-exemplar.html,,,,,
Reusability,,,Recipe1260487045291893021,recipes,2021-02-05,reusability,https://fairplus.github.io/cookbook-dev/recipes/reusability.html,,,,,
Selecting a Licensing Mode,,,Recipe4423827750435668095,recipes,2021-02-05,reusability,https://fairplus.github.io/cookbook-dev/recipes/accessibility/license-selection.html,,,,,
FAIR Assessment,,,Recipe-6116826662272333629,recipes,2021-02-05,reusability,https://fairplus.github.io/cookbook-dev/recipes/assessing-fairness.html,,,,,
FAIR indicators,,,Recipe-2154143582540716281,recipes,2021-02-05,reusability,https://fairplus.github.io/cookbook-dev/recipes/assessing-fairness/fair-indicators.html,,,,,
manual assessment,,,Recipe-7776114281579449896,recipes,2021-02-05,reusability,https://fairplus.github.io/cookbook-dev/recipes/assessing-fairness/manual-fair-assessment.html,,,,,
automatic assessment with FAIREvaluator,,,Recipe3798075358001129261,recipes,2021-02-05,reusability,https://fairplus.github.io/cookbook-dev/recipes/assessing-fairness/fair-assessment-recipe.html,,,,,
automatic assessment with FAIRshake,,,Recipe4559125501238587050,recipes,2021-02-05,reusability,https://fairplus.github.io/cookbook-dev/recipes/assessing-fairness/fair-assessment-fairshake.html,,,,,
FAIRification Examples,,,Recipe6757233359937662849,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/applied-examples.html,,,,,
FAIR data matrix Recipe,,,Recipe3304926867391601327,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/applied-examples/fair-data-matrix-recipe.html,,,,,
Converting Excel to Frictionless Data Package,,,Recipe-2248117954152308478,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/applied-examples/fair-data-matrix/0-rose-metabolites-Python-data-handling.html,,,,,
Plotting from Frictionless Data Package in Python,,,Recipe8988559078594743521,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/applied-examples/fair-data-matrix/1-rose-metabolites-Python-analysis.html,,,,,
Plotting from Frictionless Data Package in R,,,Recipe7821512408387869149,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/applied-examples/fair-data-matrix/3-rose-metabolites-R-analysis.html,,,,,
Exploration fo semantic model with SPARQL,,,Recipe972960264611274261,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/applied-examples/fair-data-matrix/2-rose-metabolites-Python-RDF-querying-analysis.html,,,,,
FAIRification of IMI datasets,,,Recipe-595738343945329572,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/fairified-imi-data.html,,,,,
eTOX experience Recipe,,,Recipe-2858543137774001763,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/applied-examples/etox_raw/FAIRplus_Recipe_Ontology_mapping_the_eTox_dataset_scenario.html,,,,,
RESOLUTE experience Recipe,,,Recipe-8119340106462267895,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/applied-examples/resolute_raw/rawRecipe_resolute.html,,,,,
ONCOTRACK experience Recipe,,,Recipe-8567303974915368915,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/applied-examples/oncotrack_raw/rawRecipe-oncotrack.html,,,,,
ND4BB experience Recipe,,,Recipe-8963796694758336701,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/applied-examples/nd4bb_raw/FAIRification_CookBook_Recipe1_V02.html,,,,,
Capability & Maturity indicators,,,Recipe1598987258895299593,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/cmmi.html,,,,,
Tools for FAIR,,,Recipe1746653655704351223,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/tools4fair.html,,,,,
Glossary,,,Recipe1133305780653144058,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/glossary-fair-terms.html,,,,,
Contributing Content,,,Recipe-1509406298822114315,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/help.html,,,,,
How to create a recipe with GoogleDoc,,,Recipe-3969746824084934391,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/help/how-to-create-recipe-with-gdoc.html,,,,,
How to use HackMD to write a FAIR Cookbook Recipe,,,Recipe1983560300531275521,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/help/how-to-create-recipe-with-hackmd.html,,,,,
HackMD Tips and Tricks,,,Recipe-6358636913980270435,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/help/tips-tricks.html,,,,,
How to create a recipe with git,,,Recipe8945079961034720791,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/help/how-to-create-recipe-with-git.html,,,,,
Recipe Template,,,Recipe1340974016590344603,recipes,2021-02-05,,https://fairplus.github.io/cookbook-dev/recipes/help/recipe-template.html,,,,,
Study level documentation is available in a human readable format.,Study-level documentation provides high-level information on the research context and design the data collection methods used any data preparations and manipulations and summaries of findings based on the data. Examples and a suggested list of coverage can be found at UK Data Services. Repurposing,,indicator4068143603170371285,indicators,2021-02-05,"interoperability, findability",,,,,,
Data is reported by following community specific minimum information guidelines,A reporting standard ensures recording the information (metadata) required to unambiguously communicate experimental designs treatments and analyses to con-textualize the data generated. Such standards are also known as data content or minimum information standards (Chervitz et all.). See examples: reporting standards for health care,,indicator3342256941028690594,indicators,2021-02-05,"reusability, accessibility",,,,,,
Metadata documents and provides references about all data biological data types and formats in data is expressed.,Biological and biomedical research has been considered an especially challenging research field in this regard as data types are extremely heterogeneous and not all have defined data standards (Griffin et. all). Metadata should capture all data types and format names in a study if possible provide a reference or URL for format specification,,indicator8273044894976530631,indicators,2021-02-05,"findability, findability",,,,,,
Relationships between different data sets in a study is well defined.,In a study there are multiple data sets which are used as input and produced as an output. When a data is FAIRified it is important to understand which data files are generated from the analysis of which other data sets or sample data. For example the EMBL-EBI SDRF (Sample and Data Relationship Format) describes the sample characteristics and the relationship between samples arrays,,indicator5324004451417711669,indicators,2021-02-05,"accessibility, findability",,,,,,
A versioning policy is applied to uniquely identify a particular form of a dataset from an earlier form or other forms of itself.,Versioning is tracking the changes made in data by saving new copies of data files with indicators of the changes made. A new version is created when there is a change in the structure contents or condition of the resource. In the case of research data a new version of a dataset may be created when an existing dataset is reprocessed,,indicator-2272968738514576769,indicators,2021-02-05,"findability, accessibility",,,,,,
Shares not only derived and publication related data but data generated in early phases of research data workflow such as primary data and analyzed data.,Life science experiments comprise different samples; based on experiment and sample several measurements are performed. After quantification there is a step of data processing and analysis which results in life science research (Colmsee et.all). In most cases data is shared with publications as supplementary files or in data repositories which are referenced by articles. However raw data and primary data resides in private storages (Arend,,indicator1787217449564683029,indicators,2021-02-05,"reusability, accessibility",,,,,,
Negative results are shared.,Negative results are the outcomes which do not support study hypotheses. Researchers are rewarded more for publishing novel findings and not for publishing negative results. However sharing negative results could reduce efforts and avoid repeating work that may be difficult to replicate (ATCC).Negative result also can be reported in publications (e.g. Negative Results Journal). Repurposing,,indicator-4965224361488258489,indicators,2021-02-05,"accessibility, reusability",,,,,,
The study is described with metadata including context, samples and data acquisition methods for analyzing and processing data quality control and restriction for reuse.,,indicator6489480779590165568,indicators,2021-02-05,"findability, accessibility",,,,,,
Metadata includes information about the study design, protocols and data collection methods.Example metadata: study / experiment design trial protocol data acquisition methods,,indicator785543140297643940,indicators,2021-02-05,"findability, findability",,,,,,
Metadata includes explicit references to research resources such as samples, cell linesProvide information about key research materials such as antibodies cell lines and organisms. Preferable with identifiers,,indicator-4930948157241142466,indicators,2021-02-05,"reusability, findability",,,,,,
Metadata contains information about data processing methods, data analysis and quality assurance metrics.See specific examples for quality requirements for In Vitro research such as chemical probes cell line authentication,,indicator-829625912951670336,indicators,2021-02-05,"accessibility, interoperability",,,,,,
Metadata includes information about data ownership, license and reuse constraints for sensitive data.Considering the sensitive nature of life science data beside data reuse license consent,,indicator8140844144853866108,indicators,2021-02-05,"findability, accessibility",,,,,,
Data is organized and documented in a human understandable way,Data-level or object-level documentation provides information at the level of variables in a database or individual objects such as images. Data-level information can be embedded in data files such as variable,,indicator-1721646150443159845,indicators,2021-02-05,"reusability, accessibility",,,,,,
Data is encoded in a community specific exchange standard.,A data exchange standard defined the encoding format of data. A data exchange standard delineates what data types can be encoded and the particular way they should be encoded (e.g. tab-delimited columns XML binary,,indicator375889843440242478,indicators,2021-02-05,"reusability, interoperability",,,,,,
A machine and human readable formal description of the structure of data is available including types, properties.A schema describes the structure of the data. Special schemes have meanings associated with databases such as community agreed profiles. A schema consists of a key dimension and its properties expected types,,indicator7820327921579184283,indicators,2021-02-05,"reusability, findability",,,,,,
Data is structured by following a life sciences domain model, core classes and their semantic relations refers to a common data  model.Meaningful exchange of information is a fundamental challenge in life sciences research. A domain model A domain is an abstract implementation-independent representation of the grammar or semantics,,indicator-2663822751181611124,indicators,2021-02-05,"accessibility, findability",,,,,,
Data is described with terminology standards.,Terminology standards is typically defined by the use cases and provides control vocabularies to support and competency questions it is designed to answer. In life sciences domain ontologies are common ways to encode terminology standards (Chervitz et all.). Terminology standards add an interpretive layer to the data by defining the concepts or terms in a domain and in some cases the relationships between them (Tenenbaum et. all). See an example list for terminology standards. For a complete listing see the OBO Foundry.Integration,,indicator-8660801326173587753,indicators,2021-02-05,"accessibility, interoperability",,,,,,
Core data classes (important data elements) follows a common master and reference data entity.,Master data is defined as core business objects used in different applications across an organization along with their associated metadata definitions and taxonomies. Reference data is used to characterize or classify other data such as codes and description tables. Master and Reference data lowers cost and complexity through use of standards common data models and integration patterns. Sharing master data within a community or in organization reduces variability caused by multiple studies producing the same type of data,,indicator-9066113219442634818,indicators,2021-02-05,"reusability, interoperability",,,,,,
Aber-OWL,"Type any term or phrase to search the AberOWL ontology repository for a class with label (try pancreas), class description containing searched phrase or part of it (try sugar binding GO), using class OBO ID (try PATO:0001234), for ontologies by acronym (try ECO) or by phrase part of ontology description (try integrated upper ontology,infectious disease, or pathology), or perform a Description Logic query (try 'part of' some 'apoptotic process' ):",,tool-1802244706507895372,tools,2021-02-05,"ontology annotation, findability",http://aber-owl.net/#/,,,,,
Alation,,,tool-8460440406676768097,tools,2021-02-05,"ontology annotation, interoperability",https://www.alation.com/,,,,,
Biobert,"This repository provides the code for fine-tuning BioBERT, a biomedical language representation model designed for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, question answering, etc. Please refer to our paper BioBERT: a pre-trained biomedical language representation model for biomedical text mining for more details. This project is done by DMIS-Lab.
",,tool-2597139327568999544,tools,2021-02-05,"ontology annotation, interoperability",https://github.com/dmis-lab/biobert,,,,,
Cantree API,,,tool1211738704062386262,tools,2021-02-05,"ontology annotation, accessibility",,,,,,
Collibra,,,tool-4047816096447411734,tools,2021-02-05,"ontology annotation, interoperability",https://www.collibra.com/,,,,,
eNanoMapper Slimmer,"Slimmer is a slim tool to slim ontologies as part of ontology integration. It allows users to provide configuration files that specify which parts of an ontology should be kept and/or removed, allowing to just select parts of the ontology you like. Rewiring the ontology is part of the features, allowing you to define new super terms.",,tool-2808344235473424905,tools,2021-02-05,"ontology annotation, reusability",https://github.com/enanomapper/slimmer,,,,,
GeneTegra,"INFOTECH Soft is dedicated to the development of state of the art software solutions for the healthcare and life science industries. Our objective is to create software solutions that enable medical and research professionals to effectively diagnose and treat patient ailments.

We specialize in the application of Semantic Web technologies to biomedical and clinical research. Coupled with a solid understanding of new and evolving technologies in network computing, high speed integrated services networks, and distributed systems architectures, our goal is to meet the information technology solutions needs of our customers.",,tool-4238721493009317882,tools,2021-02-05,"ontology annotation, interoperability",http://www.genetegra.com/,,,,,
MarkLogic,,,tool3562876621611196912,tools,2021-02-05,"ontology annotation, interoperability",https://developer.marklogic.com/concept/ontology-driven-entity-extraction/,,,,,
NCBO Bioportal,"The goal of the National Center for Biomedical Ontology is to support biomedical researchers in their knowledge-intensive work, by providing online tools and a Web portal enabling them to access, review, and integrate disparate ontological resources in all aspects of biomedical investigation and clinical practice. A major focus of our work involves the use of biomedical ontologies to aid in the management and analysis of data derived from complex experiments.
",,tool11672039196568234,tools,2021-02-05,"ontology annotation, reusability",https://bioportal.bioontology.org/,,,,,
NCBO bioportal Annotator,"The range of publicly available biomedical data is enormous and continues to rapidly expand. This expansion means that researchers now face a hurdle to extracting the data they need from the large numbers of data that are available. Biomedical researchers have turned to ontologies and terminologies to structure and annotate their data with ontology concepts for better search and retrieval. However, this annotation process cannot be easily automated and often requires expert curators. Plus, there is a lack of easy-to-use systems that facilitate the use of ontologies for annotation. The NCBO Annotator (formerly referred to as the Open Biomedical Annotator (OBA)) is an ontology-based Web service that annotates public datasets with biomedical ontology concepts based on their textual metadata. The biomedical community can use the annotator service to tag their data automatically with ontology concepts. These concepts come from the Unified Medical Language System (UMLS) Metathesaurus and the National Center for Biomedical Ontology (NCBO) BioPortal ontologies. Such annotations facilitate translational discoveries by integrating annotated data.",,tool-6760009003056553255,tools,2021-02-05,"ontology annotation, accessibility",https://bioportal.bioontology.org/annotator,,,,,
NeuralCR,"NCR is a concept recognizer for annotating unstructured text with concepts from an ontology. In its core, NCR uses a deep neural network trained to classify input phrases with concepts in a given ontology, and is capable of generalizing to synonyms not explicitly available.",,tool-4244107448249474955,tools,2021-02-05,"ontology annotation, findability",https://github.com/ccmbioinfo/NeuralCR,,,,,
OBO foundry,"The mission of the OBO Foundry is to develop a family of interoperable ontologies that are both logically well-formed and scientifically accurate. To achieve this, OBO Foundry participants follow and contribute to the development of an evolving set of principles including open use, collaborative development, non-overlapping and strictly-scoped content, and common syntax and relations, based on ontology models that work well, such as the Operations Committee with Editorial, Technical and Outreach working groups.",,tool-7725961953531878093,tools,2021-02-05,"ontology annotation, findability",http://www.obofoundry.org/,,,,,
OLS,"The Ontology for Biomedical Investigations (OBI) is build in a collaborative, international effort and will serve as a resource for annotating biomedical investigations, including the study design, protocols and instrumentation used, the data generated and the types of analysis performed on the data. This ontology arose from the Functional Genomics Investigation Ontology (FuGO) and will contain both terms that are common to all biomedical investigations, including functional genomics investigations and those that are more domain specific.",,tool93103256108442864,tools,2021-02-05,"ontology annotation, interoperability",https://www.ebi.ac.uk/ols/ontologies/obi,,,,,
Ontobee,"Ontobee: A linked data server designed for ontologies. Ontobee is aimed to facilitate ontology data sharing, visualization, query, integration, and analysis. Ontobee dynamically dereferences and presents individual ontology term URIs to (i) HTML web pages for user-friendly web browsing and navigation, and to (ii) RDF source code for Semantic Web applications. Ontobee is the default linked data server for most OBO Foundry library ontologies. Ontobee has also been used for many non",,tool-2118379673562288780,tools,2021-02-05,"ontology annotation, reusability",http://www.ontobee.org/,,,,,
OntoMaton,"OntoMaton facilitates ontology search and tagging functionalities within Google Spreadsheets. It has been developed by the ISA Team at the University of Oxford's e-Research Centre.
",,tool-1077429877939484448,tools,2021-02-05,"ontology annotation, accessibility",https://github.com/ISA-tools/OntoMaton,,,,,
OntoText,"Organize your information and documents into enterprise knowledge graphs
We make data management and analytics work in synergy:

Connect and publish complex enterprise knowledge with standard-compliant semantic graph database;
Customize and apply analytics to link documents to graphs, extract new facts, classify and recommend content;
Access data via GraphQL to ease application development.",,tool4965272688391386973,tools,2021-02-05,"ontology annotation, findability",https://www.ontotext.com/products/ontotext-platform/,,,,,
OWLAPI,"The OWL API is a Java API for creating, manipulating and serialising OWL Ontologies.",,tool-6819309560935213542,tools,2021-02-05,"ontology annotation, findability",https://github.com/owlcs/owlapi,,,,,
OXO,"OxO is a service for finding mappings (or cross-references) between terms from ontologies, vocabularies and coding standards. OxO imports mappings from a variety of sources including the Ontology Lookup Service and a subset of mappings provided by the UMLS. We're still developing the service so please get in touch if you have any feedback.",,tool5428549736443096969,tools,2021-02-05,"ontology annotation, interoperability",https://www.ebi.ac.uk/spot/oxo/,,,,,
Protege,,,tool-111406598838558556,tools,2021-02-05,"ontology annotation, accessibility",,,,,,
PoolParty,https://help.poolparty.biz/pp7/user-guide-for-knowledge-engineers/advanced-features/ontology-management-overview,,tool-2169541413414124461,tools,2021-02-05,"ontology annotation, reusability",https://www.poolparty.biz/natural-language-processing/,,,,,
rdflibs,"RDFLib is a pure Python package for working with RDF. RDFLib contains useful APIs for working with RDF, including:",,tool8345290811003156185,tools,2021-02-05,"ontology annotation, accessibility",https://rdflib.readthedocs.io/en/stable/,,,,,
ROBOT,ROBOT is a tool for working with Open Biomedical Ontologies. It can be used as a command-line tool or as a library for any language on the Java Virtual Machine.,,tool1156950162806413466,tools,2021-02-05,"ontology annotation, reusability",http://robot.obolibrary.org/,,,,,
Stardog,"Deliver faster time to insight with Stardog’s Enterprise Knowledge Graph platform.

Bring context to your data for better decision-making
Perform complex queries across silos
Seamlessly support multiple apps and data models",,tool6116818129052297940,tools,2021-02-05,"ontology annotation, accessibility",https://www.stardog.com/,,,,,
Termite (scibite) Centre,"SciBite addresses these problems with user-friendly, efficient and robust solutions which simplify collaborative ontology management and use the power of machine learning techniques to support the process of curating and enriching both internal and external ontologies.",,tool-909764664881749857,tools,2021-02-05,"ontology annotation, reusability",https://www.scibite.com/,,,,,
Topbraid Composer,"TopBraid EDG–VM creates a Knowledge Graph of your vocabularies and associated resources. A flexible, web-based system, it supports business stakeholders who need to collaborate on defining, linking and using enterprise vocabularies (such as taxonomies, thesauri and ontologies) required to integrate content sources, comply with regulations, enhance navigation and search.",,tool-8342864256361012764,tools,2021-02-05,"ontology annotation, interoperability",https://www.topquadrant.com/products/topbraid-edg-vocabulary-management/,,,,,
Virtuoso,"Virtuoso Universal Server is modern platform built on existing open standards that harnesses the power of Hyperlinks (functioning as Super Keys) for breaking down data silos that impede both user and enterprise ability . For example, Virtuoso's core SQL & SPARQL powers many Enterprise Knowledge Graph initiatives just as it does DBpedia and a majority of nodes in the Linked Open Data Cloud -- the world's largest publicly accessible Knowledge Graph.",,tool-7329472341567815243,tools,2021-02-05,"ontology annotation, reusability",https://virtuoso.openlinksw.com/,,,,,
Zooma,"Zooma is a tool for mapping free text annotations to ontology term based on a curated repository of annotation knowledge.

Where mappings are not found in the curated respository one or more ontologies can be selected from the Ontology Lookup Service to increase coverage. For example if you want to map GWAS annotations select the GWAS datasource and a common disease ontology such as EFO or DOID to maximise coverage when terms have no curated mappings.

Use the text box to find possible ontology mappings for free text terms in the ZOOMA repository of curated annotation knowledge. You can add one term (e.g. 'Homo sapiens') per line. If you also have a type for your term (e.g. 'organism'), put this after the term, separated by a tab.
If you are new to ZOOMA, take a look at our getting started guide.",,tool-8908719240678650787,tools,2021-02-05,"ontology annotation, accessibility",https://www.ebi.ac.uk/spot/zooma/,,,,,
beere,"Tool for Biomedical Entity Expansion, Ranking, and Exploration.",,tool-6162236207964484041,tools,2021-02-05,"ontology annotation, interoperability",http://discovery.informatics.uab.edu/BEERE/,,,,,
biocaddie,Leveraging word embeddings and medical entity extraction for biomedical dataset retrieval using unstructured texts. Mayo's Data for the bioCADDIE 2016 Dataset Retrieval Challenge,,tool6438044801114947699,tools,2021-02-05,"ontology annotation, reusability",https://github.com/yanshanwang/biocaddie2016mayodata,,,,,
onclass,Unifying single-cell annotations based on the Cell Ontology. Single cell typing based on cell ontology. please see the document of OnClass at https://onclass.readthedocs.io/en/latest/,,tool-4918357171446889746,tools,2021-02-05,"ontology annotation, reusability",https://onclass.readthedocs.io/en/latest/,,,,,
hpo2go,"Prediction of human phenotype ontology term associations using cross ontology annotation co-occurrences. Mapping between HPO and GO terms. If you find HPO2GO useful, please consider citing this publication:. Mapping between Human Phenotype Ontology (HPO) and Gene Ontology (GO) terms for the prediction of gene/protein - function - phenotype - disease associations. In this study, a novel approach is proposed for the identification of relationships between biomedical entities by automatically mapping phenotypic abnormality defining HPO terms with biomolecular function defining GO terms, where each association indicates the occurrence of the abnormality due to the loss of the biomolecular function expressed by the corresponding GO term",,tool-1731676583135367744,tools,2021-02-05,"ontology annotation, reusability",https://github.com/cansyl/HPO2GO,,,,,
ontobrowser,"The tool was developed to manage ontologies (and controlled terminologies e.g. CDISC SEND). The primary goal of the tool is to provide an online collaborative solution for expert curators to map code list terms (sourced from multiple systems/databases) to preferred ontology terms. Other key features include visualisation of ontologies in hierarchical/graph format, advanced search capabilities, peer review/approval workflow and web service access to data.",,tool-7989354770938286130,tools,2021-02-05,"ontology annotation, reusability",https://bio.tools/ontobrowser,,,,,
Bert,Bidirectional Encoder Representations from Transformers (BERT) is a Transformer-based machine learning technique for natural language processing (NLP) pre-training developed by Google. ,,tool-1173329963976295008,tools,2021-02-05,"ETL, accessibility",https://en.wikipedia.org/wiki/BERT_(language_model),,,,,
Collibra,Collibra Data Catalog empowers business users to quickly discover and understand data that matters so they can generate impactful insights that drive business value. Collibra Data Lineage: Collibra Data Lineage automatically maps relationships between data to show how data flows from system to system and how data sets are built,,tool-4047816096447411734,tools,2021-02-05,"ETL, findability", aggregated,,,,,
Dublin Core,The Dublin Core Metadata Initiative or DCMI is an organization supporting innovation in metadata design and best practices across the metadata ecology. DCMI works openly and it supported by a paid-membership model. DCMI's activities include: work on architecture and modelling,,tool5605130047360711530,tools,2021-02-05,"ETL, findability",https://dublincore.org/,,,,,
Hadoop,a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines,,tool5168613560416533892,tools,2021-02-05,"ETL, accessibility", each offering local computation and storage. Rather than rely on hardware to deliver high-availability,,,,,
Informatica,Informatica is the only Enterprise Cloud Data Management leader that accelerates data-driven digital transformation. Informatica enables companies to fuel innovation become more agile and realize new growth opportunities resulting in intelligent market disruptions,,tool-1093164953604752218,tools,2021-02-05,"ETL, reusability",https://www.informatica.com/gb/about-us.html,,,,,
OMOP,The OMOP Common Data Model allows for the systematic analysis of disparate observational databases. The concept behind this approach is to transform data contained within those databases into a common format (data model) as well as a common representation (terminologies vocabularies coding schemes) and then perform systematic analyses using a library of standard analytic routines that have been written based on the common format,,tool6773208910100621388,tools,2021-02-05,"ETL, interoperability",https://www.ohdsi.org/data-standardization/the-common-data-model/,,,,,
REDCap,REDCap is a secure web application for building and managing online surveys and databases. While REDCap can be used to collect virtually any type of data in any environment (including compliance with 21 CFR Part 11 FISMA HIPAA and GDPR),,tool971227232691534242,tools,2021-02-05,"ETL, accessibility",https://www.project-redcap.org/,,,,,
SDTM,SDTM provides a standard for organizing and formatting data to streamline processes in collection management analysis and reporting. Implementing SDTM supports data aggregation and warehousing; fosters mining and reuse; facilitates sharing; helps perform due diligence and other important data review activities; and improves the regulatory review and approval process. SDTM is also used in non-clinical data (SEND) medical devices and pharmacogenomics/genetics studies.,,tool6865448652550866976,tools,2021-02-05,"ETL, interoperability",https://www.cdisc.org/standards/foundational/sdtm,,,,,
TAMR,Accelerating Analytic outcomes. The toughest analytics challenges need consolidated cleansed categorized data. Tamr’s data mastering solutions are designed to power timely actionable analytic insightsCloud-Native Master. Data Management (MDM). Tamr’s cloud-native data mastering solutions make it easy to connect internal and external data sources quickly to power analytic insights and drive business outcomes,,tool-3757409349378717183,tools,2021-02-05,"ETL, findability",https://www.tamr.com/,,,,,
TransMART,An Open-Source—Open-Data Community. Enabling collaboration for precision medicine through sharing integration standardization,,tool-6889793941815152999,tools,2021-02-05,"ETL, reusability",https://i2b2transmart.org/,,,,,
TriFacta,Poor data quality can sink any analytics project. Trifacta helps you understand your data so you can quickly and accurately clean it up. Clean Blend & Standardize your Data. Data transformation. All the power with none of the code. Trifacta provides visual and intelligent guidance so you can get to insights faster.Automate Your Data Processes. Data pipelines. Manual repetitive data preparation processes don’t scale. Trifacta helps you build deploy and manage self-service data pipelines in minutes not months.,,tool828355421769954463,tools,2021-02-05,"ETL, accessibility",https://www.trifacta.com/,,,,,
Termite,TERMite (TERM identification,,tool-4544028877615330347,tools,2021-02-05,"ETL, accessibility",,,,,,
fairifier,A general-purpose FAIRifier on the basis of the OpenRefine data cleaning and wrangling tool and the RDF plugin. This FAIRifier enables a post-hoc FAIRification workflow: load an existing dataset,,tool-2985223437548704761,tools,2021-02-05,"ETL, findability",,,,,,
query tabular,galaxy only,,tool-8650457348792010915,tools,2021-02-05,"ETL, interoperability",,,,,,
martview,Tool for data retrieval and data mining that integrates data from Ensembl. Through the web interface it allows you to apply a series of filters to create custom datasets which can be converted to several useful output formats.,,tool-2245596179367195657,tools,2021-02-05,"ETL, interoperability",,,,,,
osirix,OsiriX is an image processing software dedicated to DICOM images (“.dcm” / “.DCM” extension) produced by imaging equipment (MRI,,tool-5927044756952364085,tools,2021-02-05,"ETL, findability",,,,,,
ms-data-core-api,The ms-data-core-api is a free,,tool4940931381669193674,tools,2021-02-05,"ETL, reusability",,,,,,
snpator,deprecated,,tool180773408246401237,tools,2021-02-05,"ETL, reusability",,,,,,
disqover,DISQOVER is a data integration platform for public,,tool-5607621352020703842,tools,2021-02-05,"ETL, findability",,,,,,
